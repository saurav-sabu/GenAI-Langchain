{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install necessary packages"
      ],
      "metadata": {
        "id": "gVVoN0sdvICb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTPTTFqRFKk1"
      },
      "outputs": [],
      "source": [
        "! pip install pypdf\n",
        "! pip install sentence-transformers==2.2.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install langchain-openai\n",
        "! pip install tiktoken\n",
        "! pip install faiss-cpu"
      ],
      "metadata": {
        "id": "wKaVn02sGRGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U langchain-community"
      ],
      "metadata": {
        "id": "VSADm7fPIOxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Data"
      ],
      "metadata": {
        "id": "Bg1-7YVWvOSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the PDF loader from langchain_community\n",
        "from langchain_community.document_loaders import PyPDFDirectoryLoader"
      ],
      "metadata": {
        "id": "dyaNMCZlG6bs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load PDF documents from a specified directory\n",
        "loader = PyPDFDirectoryLoader(\"llm\")\n",
        "\n",
        "data = loader.load() # Load all PDF documents"
      ],
      "metadata": {
        "id": "2JzEKyPFIL2u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display loaded data\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU158CmwIbuu",
        "outputId": "2b0c83f4-e5a5-4ae5-de7b-6f8a63fe3c2e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Generative AI ', metadata={'source': 'llm/Generative AI.pdf', 'page': 0}),\n",
              " Document(page_content='What you will learn? \\n●Generative AI? \\n●Large Language Models (LLMs) \\n●OpenAI \\n●Langchain \\n●Vector Database \\n●Llama Index \\n●Open Source LLM model \\n●End to End Project ', metadata={'source': 'llm/Generative AI.pdf', 'page': 1}),\n",
              " Document(page_content='Generative AI \\n●ChatGPT \\n●Google Bard \\n●Meta Llama 2 ', metadata={'source': 'llm/Generative AI.pdf', 'page': 2}),\n",
              " Document(page_content='What is Generative AI? \\nGenerative AI generate new data based on training sample.Generative model \\ncan generate Image,Text, Audio, Videos etc. data as output. \\nSo generative AI is a very huge topics, \\n-Generative Image model \\n-Generative Language model ', metadata={'source': 'llm/Generative AI.pdf', 'page': 3}),\n",
              " Document(page_content='Generative Model: \\nQuestions R esponses ', metadata={'source': 'llm/Generative AI.pdf', 'page': 4}),\n",
              " Document(page_content='Where Generative AI Exists. \\n●Machine Learning is the subset of Artiﬁcial \\nIntelligence \\n●Deep Learning is the subset of Machine Learning \\n●Generative AI is the subset of Deep Learning ', metadata={'source': 'llm/Generative AI.pdf', 'page': 5}),\n",
              " Document(page_content='Discriminative vs Generative Model \\n', metadata={'source': 'llm/Generative AI.pdf', 'page': 6}),\n",
              " Document(page_content='Discriminative vs Generative Model \\n', metadata={'source': 'llm/Generative AI.pdf', 'page': 7}),\n",
              " Document(page_content='Clustering: \\n●K-Means \\n●DBScan \\nClassiﬁcation & Regression: \\n', metadata={'source': 'llm/Generative AI.pdf', 'page': 8}),\n",
              " Document(page_content=\"Generative AI is a subset of deep learning and Generative models are trained on huge amount \\nof data. While training the generative model we don’t need to provide a label data, It is not possible \\nwhen we have a huge amount of data, So, it's just try to see the relationship between the distribution \\nof the data. In Generative AI we give unstructured data to the LLM model for training purpose. \\n\", metadata={'source': 'llm/Generative AI.pdf', 'page': 9}),\n",
              " Document(page_content='What is LLMs? \\nLarge Language Models (LLMs) are foundational machine learning models that use deep learning  \\nalgorithms to process and understand natural language. These models are trained on massive amounts  \\nof text data to learn patterns and entity relationships in the language.  \\nIt is a language  model which is responsible for performing task such as text to text generation  , text to  \\nimage generation  and image to text generations .', metadata={'source': 'llm/Generative AI.pdf', 'page': 10}),\n",
              " Document(page_content='What makes LLM so Powerful? \\n●In case of LLM, one model can be used for a whole variety of tasks like:- \\nText generation, Chatbot, summarizer, translation, code generation \\n& so on … \\nSo, LLM is subset of Deep Learning & it has some properties merge with \\nGenerative AI ', metadata={'source': 'llm/Generative AI.pdf', 'page': 11}),\n",
              " Document(page_content='', metadata={'source': 'llm/Generative AI.pdf', 'page': 12}),\n",
              " Document(page_content='Thank You! ', metadata={'source': 'llm/Generative AI.pdf', 'page': 13}),\n",
              " Document(page_content='Why LLM so Powerful? \\n●Train the model for a speciﬁc task \\n', metadata={'source': 'llm/Generative AI.pdf', 'page': 14}),\n",
              " Document(page_content='Few milestone in large language model \\n●Bard \\n●GPT\\n●XLM \\n●T5\\n●M2M-100 ', metadata={'source': 'llm/Generative AI.pdf', 'page': 15})]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the text splitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "-QgiNDu2InLh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the documents into chunks for embedding\n",
        "text_split = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=20)\n",
        "chunks = text_split.split_documents(data)"
      ],
      "metadata": {
        "id": "_TIiTHINIwiD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the number of chunks\n",
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRFn2p6uI6Zd",
        "outputId": "8d43f709-5f90-4c3d-a556-2be9ebb7f402"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the first chunk\n",
        "chunks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL9vps4FI7xF",
        "outputId": "d0b03e3a-4aef-4c3f-d5c9-8f37f1f36456"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Generative AI', metadata={'source': 'llm/Generative AI.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Embedding"
      ],
      "metadata": {
        "id": "9jxCjiOVvf5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the HuggingFace embedding model\n",
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "-Pl03tl3I9kP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the embedding model\n",
        "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "z6E0Oc2rKiB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the Vector Database"
      ],
      "metadata": {
        "id": "Zl70WAjdwQkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import FAISS vector store from langchain\n",
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "3N7thB97KlFN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a FAISS vector store from the document chunks and embeddings\n",
        "vectorstore = FAISS.from_documents(chunks,embedding)"
      ],
      "metadata": {
        "id": "L_P0wzpDLSQk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the vector store\n",
        "vectorstore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geqxY0rXLW0G",
        "outputId": "ec57ae17-3838-409b-b23c-bdcd6795cddd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.faiss.FAISS at 0x7b7bc5102e00>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a similarity search on the vector store\n",
        "query = \"What is LLM?\"\n",
        "docs = vectorstore.similarity_search(query,k=3)  # Retrieve top 3 relevant documents\n",
        "print(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hfLCDkGLa4Z",
        "outputId": "78109d37-9cb4-44d8-c582-575f32d7d59c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='What is LLMs? \\nLarge Language Models (LLMs) are foundational machine learning models that use deep learning  \\nalgorithms to process and understand natural language. These models are trained on massive amounts  \\nof text data to learn patterns and entity relationships in the language.  \\nIt is a language  model which is responsible for performing task such as text to text generation  , text to  \\nimage generation  and image to text generations .', metadata={'source': 'llm/Generative AI.pdf', 'page': 10}), Document(page_content='Why LLM so Powerful? \\n●Train the model for a speciﬁc task', metadata={'source': 'llm/Generative AI.pdf', 'page': 14}), Document(page_content='What makes LLM so Powerful? \\n●In case of LLM, one model can be used for a whole variety of tasks like:- \\nText generation, Chatbot, summarizer, translation, code generation \\n& so on … \\nSo, LLM is subset of Deep Learning & it has some properties merge with \\nGenerative AI', metadata={'source': 'llm/Generative AI.pdf', 'page': 11})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the retrieved documents\n",
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xX4u9J5LkAA",
        "outputId": "572d047b-0366-4d12-9c6f-3b36a98ff2d9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up the Environment"
      ],
      "metadata": {
        "id": "F8hwrYmRwYNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import userdata from google.colab to retrieve OpenAI API key\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve OpenAI API key from user data\n",
        "OPEN_AI_KEY = userdata.get('OPEN_AI_KEY')"
      ],
      "metadata": {
        "id": "u4jdQVRKLs5u"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "# Set the OpenAI API key as an environment variable\n",
        "os.environ['OPENAI_API_KEY'] = OPEN_AI_KEY"
      ],
      "metadata": {
        "id": "kEPvTBbjL1pp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up LLM"
      ],
      "metadata": {
        "id": "QhR05wTEwe8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import OpenAI from langchain_openai\n",
        "from langchain_openai import OpenAI"
      ],
      "metadata": {
        "id": "hw3Rt-cmL9ca"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the OpenAI language model\n",
        "llm = OpenAI()"
      ],
      "metadata": {
        "id": "W7-QkzOYMCTE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Chain"
      ],
      "metadata": {
        "id": "64KKRrYywjoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import RetrievalQA chain from langchain\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "-cbOdGvGMHoz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a retrieval-based QA system\n",
        "chain_llm = RetrievalQA.from_chain_type(llm,chain_type=\"stuff\",retriever=vectorstore.as_retriever())"
      ],
      "metadata": {
        "id": "5enZd0bZMNjC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Response"
      ],
      "metadata": {
        "id": "M2Y2epPCw99o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a QA query using the chain\n",
        "chain_llm.invoke(\"What is llm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MADBX-MZMZ0n",
        "outputId": "297a2ad3-abdc-498c-be7a-2210dfe305c1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'What is llm',\n",
              " 'result': ' LLM stands for Large Language Models and it is a powerful machine learning model that is trained on massive amounts of text data to understand natural language and perform various tasks such as text to text generation, chatbot, summarization, translation, and code generation. LLM is a subset of deep learning and is a type of generative AI that does not require labeled data during training. '}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}