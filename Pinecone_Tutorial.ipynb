{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install necessary packages"
      ],
      "metadata": {
        "id": "ZL-U1_V3Wobd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0sWa7vMuZDa"
      },
      "outputs": [],
      "source": [
        "! pip install langchain\n",
        "! pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sentence-transformers==2.2.2"
      ],
      "metadata": {
        "id": "1K0Wl3O7eQeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install langchain-openai"
      ],
      "metadata": {
        "id": "q1lBWiTSrS5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install langchain-pinecone"
      ],
      "metadata": {
        "id": "BxipyVqokmh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U langchain-community"
      ],
      "metadata": {
        "id": "vcuxV5HgfjFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load PDF documents from a directory"
      ],
      "metadata": {
        "id": "NgxrH2UzWvax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader"
      ],
      "metadata": {
        "id": "CigA0tnHfasy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFDirectoryLoader(\"pdf\")\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "2vq_ZbTOfhDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the documents into chunks for embedding"
      ],
      "metadata": {
        "id": "bS6w896YWzgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "XMxG_ZphfpSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_split = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
        "chunks = text_split.split_documents(data)"
      ],
      "metadata": {
        "id": "Go-4trBTf2fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDwMv1Kjf_-i",
        "outputId": "2d48f24d-bf85-41d1-8e4a-38c642436d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='LLMs', metadata={'source': 'pdf/LLMs.pdf', 'page': 0}),\n",
              " Document(page_content='What is LLMs? \\nA large Language model is a trained deep learning model that understands \\nand generate text in a human like fashion. \\nLLMs are good at Understanding and generating human language', metadata={'source': 'pdf/LLMs.pdf', 'page': 1}),\n",
              " Document(page_content='Why we call it Large Language Model? \\nBecause of the size and complexity of the Neural Network as well as the size \\nof the dataset that it was trained on. \\nResearchers started to make these models large and trained on huge datasets \\nThat they started showing impressive results like understanding complex \\nNatural Language and generating language more eloquently than ever.', metadata={'source': 'pdf/LLMs.pdf', 'page': 2}),\n",
              " Document(page_content='What makes LLM so Powerful? \\n●In case of LLM, one model can be used for a whole variety of tasks like:- \\nText generation, Chatbot, summarizer, translation, code generation \\n& so on … \\nSo, LLM is subset of Deep Learning & it has some properties merge with \\nGenerative AI', metadata={'source': 'pdf/LLMs.pdf', 'page': 3}),\n",
              " Document(page_content='LLMs Model Architecture \\nLarge Language models are based on transformer a type of Neural Network \\nArchitecture invented by Google.', metadata={'source': 'pdf/LLMs.pdf', 'page': 4}),\n",
              " Document(page_content='Few milestone in large language model \\n●BERT: Bidirectional Encoder Representations from Transformers (BERT) was developed by \\nGoogle \\n●GPT: GPT stands for \"Generative Pre-trained Transformer\".The model was developed by \\nOpenAI \\n●XLM: Cross-lingual Language Model Pretraining by Guillaume Lample, Alexis Conneau. \\n●T5: The Text-to-Text Transfer Transformer It was created by Google AI \\n●Megatron: Megatron is a large, powerful transformer developed by the Applied Deep Learning', metadata={'source': 'pdf/LLMs.pdf', 'page': 5}),\n",
              " Document(page_content='Research team at NVIDIA \\n●M2M- 100: multilingual encoder-decoder (seq-to-seq) model researchers at Facebook', metadata={'source': 'pdf/LLMs.pdf', 'page': 5}),\n",
              " Document(page_content='Transformer Tree', metadata={'source': 'pdf/LLMs.pdf', 'page': 6}),\n",
              " Document(page_content='OpenAI Based LLM models', metadata={'source': 'pdf/LLMs.pdf', 'page': 7}),\n",
              " Document(page_content='Other Open Source Models \\n●BLOOM \\n●Llama 2 \\n●PaLM \\n●Falcon \\n●Claude \\n●MPT-30B \\n●Stablelm \\nSo on ….', metadata={'source': 'pdf/LLMs.pdf', 'page': 8}),\n",
              " Document(page_content='What can LLMs be used for? \\n●Text Classiﬁcation \\n●Text Generation \\n●Text Summarization \\n●Conversation AI like chatbot, Question Answering \\n●Speech recognition and Speech identiﬁcation \\n●Spelling Corrector \\nSo on……', metadata={'source': 'pdf/LLMs.pdf', 'page': 9}),\n",
              " Document(page_content='Prompt Designing', metadata={'source': 'pdf/LLMs.pdf', 'page': 10}),\n",
              " Document(page_content='How ChatGPT was trained? \\nInternally using a LLM which is gpt-3.5 or gpt-4 \\nIt has trained on a large amount of data which is available all over the internet. \\n1.Generative pre-training \\n2.Supervised fine-tuning \\n3.Reinforcement learning', metadata={'source': 'pdf/LLMs.pdf', 'page': 11}),\n",
              " Document(page_content='Generative Pre-Training', metadata={'source': 'pdf/LLMs.pdf', 'page': 13}),\n",
              " Document(page_content='Supervised Fine-Tuning (SFT)', metadata={'source': 'pdf/LLMs.pdf', 'page': 14}),\n",
              " Document(page_content='Reinforcement Learning through Human Feedback \\n(RLHF)', metadata={'source': 'pdf/LLMs.pdf', 'page': 15}),\n",
              " Document(page_content='Reference i used: \\nhttps://www.linkedin.com/pulse/discover-how-chatgpt-istrained-pradeep-men\\non/', metadata={'source': 'pdf/LLMs.pdf', 'page': 16})]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display the number of chunks and the first chunk"
      ],
      "metadata": {
        "id": "3lr5GilDW4QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjapudbegArp",
        "outputId": "e1a8b278-b8c7-4809-afba-54589485a07d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8180dm4rgBiw",
        "outputId": "af61162f-7313-444d-b073-859927d66120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='LLMs', metadata={'source': 'pdf/LLMs.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding setup using HuggingFace"
      ],
      "metadata": {
        "id": "iFIoM09GgVrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "BMMB4KbxgIu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89zNxhtugZv_",
        "outputId": "487514f7-992c-4738-e889-ca4ab771f16e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.embed_query(\"My name is saurav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqaOkc4KgnPm",
        "outputId": "4e319cd7-2160-441a-c434-003a61b858db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.08500086516141891,\n",
              " -0.038315851241350174,\n",
              " -0.0669478252530098,\n",
              " 0.05940002202987671,\n",
              " -0.020271778106689453,\n",
              " -0.01642041653394699,\n",
              " 0.11205471307039261,\n",
              " 0.005068871192634106,\n",
              " 0.0358060747385025,\n",
              " -0.007086039986461401,\n",
              " -0.05973895639181137,\n",
              " -0.1300876885652542,\n",
              " 0.09283287078142166,\n",
              " -0.02410919964313507,\n",
              " -0.024292904883623123,\n",
              " -0.07286591082811356,\n",
              " 0.015663256868720055,\n",
              " 0.02348797209560871,\n",
              " -0.034784287214279175,\n",
              " -0.05830112099647522,\n",
              " -0.026543153449892998,\n",
              " 0.014836865477263927,\n",
              " -0.02004057914018631,\n",
              " -0.025269029662013054,\n",
              " -0.005322557408362627,\n",
              " -0.0052007646299898624,\n",
              " -0.03501150757074356,\n",
              " 0.02824602648615837,\n",
              " -0.03221040591597557,\n",
              " -0.0296953022480011,\n",
              " 0.06138113513588905,\n",
              " -0.01424354873597622,\n",
              " 0.058718711137771606,\n",
              " 0.05265409126877785,\n",
              " 0.022563448175787926,\n",
              " 0.0166702251881361,\n",
              " -0.14070264995098114,\n",
              " 0.06423964351415634,\n",
              " -0.01154333632439375,\n",
              " 0.04950723797082901,\n",
              " -0.02523973025381565,\n",
              " -0.07384567707777023,\n",
              " -0.00897225271910429,\n",
              " 0.027713479474186897,\n",
              " 0.013296977616846561,\n",
              " -0.022534802556037903,\n",
              " -0.04126982390880585,\n",
              " 0.011690843850374222,\n",
              " 0.05742725729942322,\n",
              " 0.04820014163851738,\n",
              " -0.07374062389135361,\n",
              " -0.08860932290554047,\n",
              " -0.05291149765253067,\n",
              " 0.02643914893269539,\n",
              " -0.014061933383345604,\n",
              " -0.03409363701939583,\n",
              " -0.041612934321165085,\n",
              " 0.008401366882026196,\n",
              " 0.03902224823832512,\n",
              " 0.014773725531995296,\n",
              " 0.011018943972885609,\n",
              " 0.028465984389185905,\n",
              " -0.04437252879142761,\n",
              " -0.008684445172548294,\n",
              " -0.03552237153053284,\n",
              " -0.03522340580821037,\n",
              " 0.027467066422104836,\n",
              " 0.032471343874931335,\n",
              " 0.02752317301928997,\n",
              " 0.05060223489999771,\n",
              " 0.012441031634807587,\n",
              " 0.03665899857878685,\n",
              " 0.010043109767138958,\n",
              " 0.06988038867712021,\n",
              " 0.0018116917926818132,\n",
              " -0.03929448127746582,\n",
              " 0.034996118396520615,\n",
              " -0.015328338369727135,\n",
              " 0.02613702043890953,\n",
              " 0.06177432835102081,\n",
              " -0.05803846940398216,\n",
              " -0.02342250756919384,\n",
              " -0.12282650172710419,\n",
              " -0.02009214647114277,\n",
              " -0.027081789448857307,\n",
              " 0.03501679748296738,\n",
              " 0.015843547880649567,\n",
              " -0.011276538483798504,\n",
              " -0.022717779502272606,\n",
              " -0.05961775779724121,\n",
              " -0.0010251915082335472,\n",
              " -0.024716688320040703,\n",
              " 0.04424547404050827,\n",
              " -0.044152118265628815,\n",
              " 0.008724384009838104,\n",
              " -0.05230240523815155,\n",
              " 0.006331585813313723,\n",
              " 0.013452527113258839,\n",
              " -0.08121506869792938,\n",
              " 0.10616075992584229,\n",
              " -0.02416815049946308,\n",
              " -0.035585954785346985,\n",
              " 0.027758345007896423,\n",
              " 0.03896826505661011,\n",
              " 0.010489188134670258,\n",
              " 0.06876564770936966,\n",
              " -0.005291931331157684,\n",
              " 0.005499046295881271,\n",
              " -0.025725163519382477,\n",
              " -0.05843903869390488,\n",
              " -0.046985380351543427,\n",
              " 0.022647423669695854,\n",
              " -0.051900047808885574,\n",
              " 0.049997638911008835,\n",
              " 0.05400410294532776,\n",
              " 0.044524677097797394,\n",
              " 0.0261211059987545,\n",
              " -0.014816981740295887,\n",
              " -0.055454034358263016,\n",
              " -0.07132528722286224,\n",
              " -0.021115129813551903,\n",
              " 0.010569705627858639,\n",
              " -0.08565327525138855,\n",
              " -0.035284191370010376,\n",
              " -0.035708144307136536,\n",
              " -0.03736785799264908,\n",
              " 0.018999716266989708,\n",
              " -1.203010745029618e-33,\n",
              " -0.06482436507940292,\n",
              " -0.02359127625823021,\n",
              " -0.017661208286881447,\n",
              " 0.06957820802927017,\n",
              " -0.04114460200071335,\n",
              " -0.014248576946556568,\n",
              " -0.0007285597384907305,\n",
              " 0.04905102029442787,\n",
              " -0.12017728388309479,\n",
              " -0.04789264500141144,\n",
              " 0.003107976634055376,\n",
              " 0.010712392628192902,\n",
              " -0.04533642157912254,\n",
              " 0.0033689814154058695,\n",
              " 0.010207081213593483,\n",
              " 0.07641024887561798,\n",
              " 0.04167584702372551,\n",
              " -0.03762509301304817,\n",
              " -0.03598605841398239,\n",
              " 0.03813324123620987,\n",
              " -0.0739809200167656,\n",
              " -0.03009256348013878,\n",
              " 0.05347440019249916,\n",
              " 0.0446242094039917,\n",
              " -0.023540563881397247,\n",
              " -0.12081588059663773,\n",
              " 0.006348127499222755,\n",
              " -0.09240374714136124,\n",
              " 0.02471819519996643,\n",
              " 0.05051996558904648,\n",
              " 0.07252395898103714,\n",
              " 0.033897560089826584,\n",
              " 0.03527816757559776,\n",
              " 0.01273574959486723,\n",
              " 0.023326629772782326,\n",
              " 0.016887648031115532,\n",
              " -0.00011462942347861826,\n",
              " -0.07556252181529999,\n",
              " -0.03199974447488785,\n",
              " 0.09916942566633224,\n",
              " 0.09203494340181351,\n",
              " 0.044602204114198685,\n",
              " -0.05852457508444786,\n",
              " 0.03222857788205147,\n",
              " 0.009328793734312057,\n",
              " 0.027694279327988625,\n",
              " 0.0798172876238823,\n",
              " -0.0005484482389874756,\n",
              " -0.026609934866428375,\n",
              " -0.040547069162130356,\n",
              " -0.08467596769332886,\n",
              " -0.010555475950241089,\n",
              " -0.06640666723251343,\n",
              " 0.050742294639348984,\n",
              " -0.08260934799909592,\n",
              " -0.0027770427986979485,\n",
              " 0.027890324592590332,\n",
              " -0.00948940496891737,\n",
              " -0.0977984294295311,\n",
              " -0.040999338030815125,\n",
              " -0.03180425614118576,\n",
              " -0.016840152442455292,\n",
              " -0.03923734277486801,\n",
              " 0.00924256257712841,\n",
              " 0.014720073901116848,\n",
              " -0.026870913803577423,\n",
              " 0.05614018067717552,\n",
              " 0.00599420303478837,\n",
              " 0.0562962181866169,\n",
              " -0.0937281921505928,\n",
              " -0.01814420521259308,\n",
              " -0.0009469680953770876,\n",
              " -0.0177982896566391,\n",
              " 0.12012894451618195,\n",
              " 0.06482493132352829,\n",
              " -0.00782506912946701,\n",
              " -0.02038336545228958,\n",
              " 0.020664865151047707,\n",
              " -0.02555471658706665,\n",
              " 0.047735679894685745,\n",
              " -0.016198821365833282,\n",
              " 0.062394361943006516,\n",
              " -0.03257543966174126,\n",
              " 0.021934324875473976,\n",
              " 0.058943334966897964,\n",
              " -0.00984716322273016,\n",
              " -0.02702009305357933,\n",
              " -0.08772066235542297,\n",
              " -0.08320042490959167,\n",
              " -0.0501699261367321,\n",
              " -0.04905598238110542,\n",
              " 0.014498119242489338,\n",
              " 0.10416730493307114,\n",
              " -0.032259292900562286,\n",
              " -0.07509559392929077,\n",
              " -4.969610719883129e-35,\n",
              " -0.0112982839345932,\n",
              " -0.04192804917693138,\n",
              " 0.036341000348329544,\n",
              " 0.07199642807245255,\n",
              " -0.008302832953631878,\n",
              " -0.008445587940514088,\n",
              " 0.09136960655450821,\n",
              " 0.12165618687868118,\n",
              " -0.042701154947280884,\n",
              " 0.045850906521081924,\n",
              " 0.08046171814203262,\n",
              " -0.025825656950473785,\n",
              " 0.013297547586262226,\n",
              " -0.02295888029038906,\n",
              " 0.11743059754371643,\n",
              " 0.016403593122959137,\n",
              " 0.08937623351812363,\n",
              " 0.041660673916339874,\n",
              " -0.0189317986369133,\n",
              " 0.00854159239679575,\n",
              " -0.051233187317848206,\n",
              " 0.11515600234270096,\n",
              " -0.06210453063249588,\n",
              " -0.026374230161309242,\n",
              " 0.019200680777430534,\n",
              " -0.04799306020140648,\n",
              " 0.06763380020856857,\n",
              " 0.05395248159766197,\n",
              " -0.025844447314739227,\n",
              " 0.051763035356998444,\n",
              " -0.028078090399503708,\n",
              " -0.004233796149492264,\n",
              " -0.15874099731445312,\n",
              " -0.0026290875393897295,\n",
              " -0.06302663683891296,\n",
              " -0.07889622449874878,\n",
              " 0.03217539191246033,\n",
              " 0.0014231860404834151,\n",
              " -0.046249520033597946,\n",
              " -0.036529384553432465,\n",
              " 0.021511226892471313,\n",
              " 0.05692204460501671,\n",
              " -0.007496298756450415,\n",
              " 0.0561763234436512,\n",
              " -0.0006498727016150951,\n",
              " -0.0722239762544632,\n",
              " 0.00976170040667057,\n",
              " 0.07604340463876724,\n",
              " 0.060896165668964386,\n",
              " -0.04050193727016449,\n",
              " -0.0045863911509513855,\n",
              " -0.08722180873155594,\n",
              " 0.014575290493667126,\n",
              " 0.0035090565215796232,\n",
              " 0.11924638599157333,\n",
              " 0.001548468368127942,\n",
              " 0.04530820623040199,\n",
              " 0.01834624633193016,\n",
              " -0.026264958083629608,\n",
              " -0.047015480697155,\n",
              " -0.005737233906984329,\n",
              " 0.047810912132263184,\n",
              " 0.006862752139568329,\n",
              " 0.059720493853092194,\n",
              " 0.10276322811841965,\n",
              " 0.013120576739311218,\n",
              " -0.04275502637028694,\n",
              " -0.06486399471759796,\n",
              " -0.05145261809229851,\n",
              " -0.11979592591524124,\n",
              " -0.02444583550095558,\n",
              " -0.05320100486278534,\n",
              " -0.09027377516031265,\n",
              " 0.04469269514083862,\n",
              " -0.0572521835565567,\n",
              " -0.049080267548561096,\n",
              " -0.016313450410962105,\n",
              " 0.0567755401134491,\n",
              " -0.005611624103039503,\n",
              " 0.029439259320497513,\n",
              " 0.011483694426715374,\n",
              " -0.0060279760509729385,\n",
              " 0.012344107031822205,\n",
              " 0.008366075344383717,\n",
              " 0.04730929434299469,\n",
              " 0.07173548638820648,\n",
              " 0.04101993888616562,\n",
              " 0.01814362406730652,\n",
              " 0.07765175402164459,\n",
              " -0.019557006657123566,\n",
              " -0.025134198367595673,\n",
              " 0.07021921873092651,\n",
              " 0.04967263713479042,\n",
              " -0.051489781588315964,\n",
              " -0.00017919816309586167,\n",
              " -1.7421388776028834e-08,\n",
              " 0.026553988456726074,\n",
              " 0.03519377484917641,\n",
              " 0.09341801702976227,\n",
              " 0.015698814764618874,\n",
              " -0.012556648813188076,\n",
              " 0.05061151087284088,\n",
              " -0.04965462535619736,\n",
              " -0.038971196860075,\n",
              " 0.01117336843162775,\n",
              " 0.026762710884213448,\n",
              " -0.0005016225622966886,\n",
              " 0.021502133458852768,\n",
              " 0.06989720463752747,\n",
              " -0.0018938160501420498,\n",
              " 0.0558803454041481,\n",
              " -0.022146474570035934,\n",
              " 0.046134017407894135,\n",
              " 0.1281958818435669,\n",
              " -0.0008274212013930082,\n",
              " -0.02299855649471283,\n",
              " -0.012681854888796806,\n",
              " -0.013742664828896523,\n",
              " 0.020734654739499092,\n",
              " 0.02489924058318138,\n",
              " 0.03287641704082489,\n",
              " 0.0005580820725299418,\n",
              " 0.06078273057937622,\n",
              " 0.046473074704408646,\n",
              " 0.023255422711372375,\n",
              " -0.03578849136829376,\n",
              " 0.01589028164744377,\n",
              " 0.04446842521429062,\n",
              " 0.06366392970085144,\n",
              " 0.030077239498496056,\n",
              " -0.020127084106206894,\n",
              " -0.03194992244243622,\n",
              " -0.033861562609672546,\n",
              " -0.029587578028440475,\n",
              " 0.0656200498342514,\n",
              " 0.02010558918118477,\n",
              " 0.08288238197565079,\n",
              " 0.09337923675775528,\n",
              " 0.10640466213226318,\n",
              " 0.03763642534613609,\n",
              " -0.1021551862359047,\n",
              " 0.10796193033456802,\n",
              " 0.07734031975269318,\n",
              " -0.06052325293421745,\n",
              " -0.07280444353818893,\n",
              " -0.042411115020513535,\n",
              " -0.020730994641780853,\n",
              " -0.017100917175412178,\n",
              " 0.05743427947163582,\n",
              " 0.0648270770907402,\n",
              " 0.08050861209630966,\n",
              " -0.02830922231078148,\n",
              " 0.014482859522104263,\n",
              " 0.015157312154769897,\n",
              " 0.014971219003200531,\n",
              " -0.03987767547369003,\n",
              " 0.08401627093553543,\n",
              " -0.01394118182361126,\n",
              " -0.139312744140625,\n",
              " -0.04666187986731529]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embedding.embed_query(\"My name is saurav\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax26o4rngvPO",
        "outputId": "26ac6cd3-7628-4407-caf8-d53641e16d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pinecone setup"
      ],
      "metadata": {
        "id": "MmatfuKog3ZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "PINECONE_API_KEY = userdata.get('PINECONE_API_KEY')"
      ],
      "metadata": {
        "id": "6btOh0RKg11G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set the Pinecone API key in the environment variables\n",
        "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY"
      ],
      "metadata": {
        "id": "1fEtUcAmjSHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Pinecone client and create an index if it doesn't exist"
      ],
      "metadata": {
        "id": "ic6GOQ0sXF-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain.vectorstores import Pinecone as PC\n",
        "from pinecone import ServerlessSpec\n",
        "\n",
        "pc = Pinecone(\n",
        "        api_key=PINECONE_API_KEY\n",
        "    )\n",
        "\n",
        "    # Now do stuff\n",
        "if 'pinecone' not in pc.list_indexes().names():\n",
        "  pc.create_index(\n",
        "            name='pinecone',\n",
        "            dimension=384,\n",
        "            metric='cosine',\n",
        "            spec=ServerlessSpec(\n",
        "                cloud='aws',\n",
        "                region='us-east-1'\n",
        "            )\n",
        "        )\n"
      ],
      "metadata": {
        "id": "3e_6fOzliQNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the existing Pinecone index\n",
        "\n",
        "# docsearch = Pinecone.from_existing_index(index_name, embeddings)\n",
        "# docsearch"
      ],
      "metadata": {
        "id": "mLLkmeXVr36K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare document chunks for Pinecone\n",
        "doc_chunk = [t.page_content for t in chunks]\n",
        "\n",
        "# Create a Pinecone vector store from the document chunks\n",
        "doc_search = PC.from_texts(doc_chunk,embedding,index_name=\"pinecone\")"
      ],
      "metadata": {
        "id": "v4YbkwNtkzjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query the Pinecone vector store"
      ],
      "metadata": {
        "id": "Ey1XmSVTXaTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is LLM?\"\n",
        "\n",
        "docs = doc_search.similarity_search(query,k=3)"
      ],
      "metadata": {
        "id": "Lr8zpetSnbrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the retrieved documents\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_CGtHF1rExT",
        "outputId": "335411f3-a1a6-4a79-a21f-581760bbda38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='LLMs'),\n",
              " Document(page_content='What is LLMs? \\nA large Language model is a trained deep learning model that understands \\nand generate text in a human like fashion. \\nLLMs are good at Understanding and generating human language'),\n",
              " Document(page_content='What makes LLM so Powerful? \\n●In case of LLM, one model can be used for a whole variety of tasks like:- \\nText generation, Chatbot, summarizer, translation, code generation \\n& so on … \\nSo, LLM is subset of Deep Learning & it has some properties merge with \\nGenerative AI')]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI setup"
      ],
      "metadata": {
        "id": "sOKJ8oD5Xg5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI"
      ],
      "metadata": {
        "id": "M2GVB4WCrFGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPEN_AI_KEY = userdata.get('OPEN_AI_KEY')"
      ],
      "metadata": {
        "id": "Cbs2p7HgrdeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(api_key=OPEN_AI_KEY)"
      ],
      "metadata": {
        "id": "cv7YgOe3rLVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up a retrieval-based QA system"
      ],
      "metadata": {
        "id": "DixpyTBwXuq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "QAAKtR5Frpby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=doc_search.as_retriever())"
      ],
      "metadata": {
        "id": "h3VcyL3xruLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform a QA query"
      ],
      "metadata": {
        "id": "LurFnGP-Xj_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is LLM\"\n",
        "\n",
        "print(qa.invoke(query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-8TsLxHryIv",
        "outputId": "03e8ffbf-de2e-49fc-aaa8-ffe9926bf2e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'What is LLM', 'result': ' LLM stands for Large Language Model, which is a type of deep learning model that is trained to understand and generate human-like language. It can be used for various tasks such as text generation, chatbots, summarization, translation, code generation, and more. '}\n"
          ]
        }
      ]
    }
  ]
}